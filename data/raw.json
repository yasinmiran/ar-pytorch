{"torch.utils.checkpoint.CheckpointFunction": {"classes": ["RuntimeError"], "functions": ["RuntimeError", "forward", "run_function", "_get_autocast_kwargs", "detach_variable", "len", "get_device_states", "enumerate", "isinstance", "backward", "check_backward_validity", "range", "list", "set_device_states", "tuple"], "constants": [], "modules": [], "extends": ["Function"], "imports": ["warnings", "weakref", "torch", "typing"], "module_info": [], "refs": ["/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/weakref.py"], "meta": {"object_name": "CheckpointFunction", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/utils/checkpoint.py", "module_name": "torch.utils.checkpoint", "module_identifier": "torch.utils.checkpoint.CheckpointFunction"}}, "torch.autograd.function._SingleLevelFunction": {"classes": ["NotImplementedError", "FunctionMeta", "Any", "Tuple", "FunctionCtx"], "functions": ["forward", "NotImplementedError", "backward", "setup_context", "jvp"], "constants": ["_C"], "modules": [], "extends": ["_FunctionBase", "FunctionCtx", "_HookMixin", "FunctionMeta"], "imports": ["collections", "functools", "warnings", "typing", "torch"], "module_info": [{"import_identifier": "torch._C", "module_name": "torch", "object_name": "_C", "classes": ["SymInt", "SymFloat", "SymBool", "ByteStorage", "DoubleStorage", "FloatStorage", "HalfStorage", "LongStorage", "IntStorage", "ShortStorage", "CharStorage", "BoolStorage", "BFloat16Storage", "ComplexDoubleStorage", "ComplexFloatStorage", "QUInt8Storage", "QInt8Storage", "QInt32Storage", "QUInt4x2Storage", "QUInt2x4Storage", "_TorchCompileInductorWrapper"], "functions": ["_preload_cuda_deps", "_load_global_deps", "sym_not", "sym_float", "sym_int", "sym_max", "sym_min", "typename", "is_tensor", "is_storage", "set_default_device", "set_default_tensor_type", "set_default_dtype", "use_deterministic_algorithms", "are_deterministic_algorithms_enabled", "is_deterministic_algorithms_warn_only_enabled", "set_deterministic_debug_mode", "get_deterministic_debug_mode", "get_float32_matmul_precision", "set_float32_matmul_precision", "set_warn_always", "is_warn_always_enabled", "manager_path", "_assert", "compiled_with_cxx11_abi", "compile", "_register_device_module", "_sparse_coo_tensor_unsafe"]}, {"import_identifier": "torch._functorch.autograd_function", "module_name": "torch._functorch", "object_name": "autograd_function", "classes": ["CustomFunctionPyOperator", "VmapInfo", "WrappedCtx", "CtxWithSavedTensors", "CtxCustomSave"], "functions": ["custom_function_call_grad", "generate_single_level_function", "wrap_outputs_maintaining_identity", "has_overriden_vmap_rule", "validate_vmap_returns_tuple_of_two_elements", "custom_function_call_vmap", "custom_function_call_vmap_generate_rule", "custom_function_call_functionalize", "vmapify_autograd_function", "get_tangents_in_dims", "reductify", "reductify_leaf"]}, {"import_identifier": "torch.utils.hooks", "module_name": "torch.utils", "object_name": "hooks", "classes": ["RemovableHandle", "BackwardHook"], "functions": ["unserializable_hook", "warn_if_has_hooks"]}, {"import_identifier": "torch._functorch", "module_name": "torch", "object_name": "_functorch", "classes": ["SymInt", "SymFloat", "SymBool", "ByteStorage", "DoubleStorage", "FloatStorage", "HalfStorage", "LongStorage", "IntStorage", "ShortStorage", "CharStorage", "BoolStorage", "BFloat16Storage", "ComplexDoubleStorage", "ComplexFloatStorage", "QUInt8Storage", "QInt8Storage", "QInt32Storage", "QUInt4x2Storage", "QUInt2x4Storage", "_TorchCompileInductorWrapper"], "functions": ["_preload_cuda_deps", "_load_global_deps", "sym_not", "sym_float", "sym_int", "sym_max", "sym_min", "typename", "is_tensor", "is_storage", "set_default_device", "set_default_tensor_type", "set_default_dtype", "use_deterministic_algorithms", "are_deterministic_algorithms_enabled", "is_deterministic_algorithms_warn_only_enabled", "set_deterministic_debug_mode", "get_deterministic_debug_mode", "get_float32_matmul_precision", "set_float32_matmul_precision", "set_warn_always", "is_warn_always_enabled", "manager_path", "_assert", "compiled_with_cxx11_abi", "compile", "_register_device_module", "_sparse_coo_tensor_unsafe"]}], "refs": ["/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/_C.cpython-39-darwin.so", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/functools.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py", "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/utils/hooks.py", "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/_functorch/__init__.py"], "meta": {"object_name": "_SingleLevelFunction", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/autograd/function.py", "module_name": "torch.autograd.function", "module_identifier": "torch.autograd.function._SingleLevelFunction"}}, "torch.autograd.function.Function": {"classes": ["RuntimeError", "NotImplementedError", "DeprecationWarning"], "functions": ["RuntimeError", "NotImplementedError", "apply", "custom_function_call", "vmap", "super"], "constants": [], "modules": [], "extends": ["_SingleLevelFunction"], "imports": ["collections", "functools", "warnings", "typing", "torch"], "module_info": [{"import_identifier": "torch._C", "module_name": "torch", "object_name": "_C", "classes": ["SymInt", "SymFloat", "SymBool", "ByteStorage", "DoubleStorage", "FloatStorage", "HalfStorage", "LongStorage", "IntStorage", "ShortStorage", "CharStorage", "BoolStorage", "BFloat16Storage", "ComplexDoubleStorage", "ComplexFloatStorage", "QUInt8Storage", "QInt8Storage", "QInt32Storage", "QUInt4x2Storage", "QUInt2x4Storage", "_TorchCompileInductorWrapper"], "functions": ["_preload_cuda_deps", "_load_global_deps", "sym_not", "sym_float", "sym_int", "sym_max", "sym_min", "typename", "is_tensor", "is_storage", "set_default_device", "set_default_tensor_type", "set_default_dtype", "use_deterministic_algorithms", "are_deterministic_algorithms_enabled", "is_deterministic_algorithms_warn_only_enabled", "set_deterministic_debug_mode", "get_deterministic_debug_mode", "get_float32_matmul_precision", "set_float32_matmul_precision", "set_warn_always", "is_warn_always_enabled", "manager_path", "_assert", "compiled_with_cxx11_abi", "compile", "_register_device_module", "_sparse_coo_tensor_unsafe"]}, {"import_identifier": "torch._functorch.autograd_function", "module_name": "torch._functorch", "object_name": "autograd_function", "classes": ["CustomFunctionPyOperator", "VmapInfo", "WrappedCtx", "CtxWithSavedTensors", "CtxCustomSave"], "functions": ["custom_function_call_grad", "generate_single_level_function", "wrap_outputs_maintaining_identity", "has_overriden_vmap_rule", "validate_vmap_returns_tuple_of_two_elements", "custom_function_call_vmap", "custom_function_call_vmap_generate_rule", "custom_function_call_functionalize", "vmapify_autograd_function", "get_tangents_in_dims", "reductify", "reductify_leaf"]}, {"import_identifier": "torch.utils.hooks", "module_name": "torch.utils", "object_name": "hooks", "classes": ["RemovableHandle", "BackwardHook"], "functions": ["unserializable_hook", "warn_if_has_hooks"]}, {"import_identifier": "torch._functorch", "module_name": "torch", "object_name": "_functorch", "classes": ["SymInt", "SymFloat", "SymBool", "ByteStorage", "DoubleStorage", "FloatStorage", "HalfStorage", "LongStorage", "IntStorage", "ShortStorage", "CharStorage", "BoolStorage", "BFloat16Storage", "ComplexDoubleStorage", "ComplexFloatStorage", "QUInt8Storage", "QInt8Storage", "QInt32Storage", "QUInt4x2Storage", "QUInt2x4Storage", "_TorchCompileInductorWrapper"], "functions": ["_preload_cuda_deps", "_load_global_deps", "sym_not", "sym_float", "sym_int", "sym_max", "sym_min", "typename", "is_tensor", "is_storage", "set_default_device", "set_default_tensor_type", "set_default_dtype", "use_deterministic_algorithms", "are_deterministic_algorithms_enabled", "is_deterministic_algorithms_warn_only_enabled", "set_deterministic_debug_mode", "get_deterministic_debug_mode", "get_float32_matmul_precision", "set_float32_matmul_precision", "set_warn_always", "is_warn_always_enabled", "manager_path", "_assert", "compiled_with_cxx11_abi", "compile", "_register_device_module", "_sparse_coo_tensor_unsafe"]}], "refs": ["/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/_C.cpython-39-darwin.so", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/functools.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py", "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/utils/hooks.py", "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/_functorch/__init__.py"], "meta": {"object_name": "Function", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/autograd/function.py", "module_name": "torch.autograd.function", "module_identifier": "torch.autograd.function.Function"}}, "torch.nn.modules.activation.ReLU": {"classes": ["F", "Module", "Tensor"], "functions": ["super", "extra_repr", "forward"], "constants": [], "modules": [], "extends": ["Module"], "imports": ["module", null, "warnings", "typing", "linear", "torch"], "module_info": [{"import_identifier": "torch.nn.parameter", "module_name": "torch.nn", "object_name": "parameter", "classes": ["_ParameterMeta", "Parameter", "UninitializedTensorMixin", "UninitializedParameter", "UninitializedBuffer"], "functions": ["is_lazy"]}, {"import_identifier": "torch.nn.init", "module_name": "torch.nn", "object_name": "init", "classes": [], "functions": ["_no_grad_uniform_", "_no_grad_normal_", "_no_grad_trunc_normal_", "_no_grad_fill_", "_no_grad_zero_", "calculate_gain", "uniform_", "normal_", "trunc_normal_", "constant_", "ones_", "zeros_", "eye_", "dirac_", "_calculate_fan_in_and_fan_out", "xavier_uniform_", "xavier_normal_", "_calculate_correct_fan", "kaiming_uniform_", "kaiming_normal_", "orthogonal_", "sparse_", "_make_deprecate"]}], "refs": ["/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py"], "meta": {"object_name": "ReLU", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/modules/activation.py", "module_name": "torch.nn.modules.activation", "module_identifier": "torch.nn.modules.activation.ReLU"}}, "torch.nn.modules.activation.Threshold": {"classes": ["F", "Module", "Tensor"], "functions": ["super", "extra_repr", "forward"], "constants": [], "modules": [], "extends": ["Module"], "imports": ["module", null, "warnings", "typing", "linear", "torch"], "module_info": [{"import_identifier": "torch.nn.parameter", "module_name": "torch.nn", "object_name": "parameter", "classes": ["_ParameterMeta", "Parameter", "UninitializedTensorMixin", "UninitializedParameter", "UninitializedBuffer"], "functions": ["is_lazy"]}, {"import_identifier": "torch.nn.init", "module_name": "torch.nn", "object_name": "init", "classes": [], "functions": ["_no_grad_uniform_", "_no_grad_normal_", "_no_grad_trunc_normal_", "_no_grad_fill_", "_no_grad_zero_", "calculate_gain", "uniform_", "normal_", "trunc_normal_", "constant_", "ones_", "zeros_", "eye_", "dirac_", "_calculate_fan_in_and_fan_out", "xavier_uniform_", "xavier_normal_", "_calculate_correct_fan", "kaiming_uniform_", "kaiming_normal_", "orthogonal_", "sparse_", "_make_deprecate"]}], "refs": ["/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py"], "meta": {"object_name": "Threshold", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/modules/activation.py", "module_name": "torch.nn.modules.activation", "module_identifier": "torch.nn.modules.activation.Threshold"}}, "torch.nn.modules.conv._ConvNd": {"classes": ["Module", "Union", "Tuple", "Parameter", "Tensor", "Optional", "List", "ValueError"], "functions": ["extra_repr", "len", "isinstance", "_reverse_repeat_tuple", "zip", "_conv_forward", "Parameter", "reset_parameters", "hasattr", "super", "ValueError", "range", "any"], "constants": [], "modules": [], "extends": ["Module"], "imports": ["module", null, "math", "lazy", "warnings", "utils", "torch.nn.parameter", "typing", "torch", "common_types", "torch._torch_docs"], "module_info": [{"import_identifier": "torch.nn.parameter", "module_name": "torch.nn", "object_name": "parameter", "classes": ["_ParameterMeta", "Parameter", "UninitializedTensorMixin", "UninitializedParameter", "UninitializedBuffer"], "functions": ["is_lazy"]}], "refs": ["/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/lib-dynload/math.cpython-39-darwin.so", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", null, null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py"], "meta": {"object_name": "_ConvNd", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/modules/conv.py", "module_name": "torch.nn.modules.conv", "module_identifier": "torch.nn.modules.conv._ConvNd"}}, "torch.nn.modules.conv.Conv1d": {"classes": ["Optional", "Tensor", "F", "Union"], "functions": ["forward", "isinstance", "_conv_forward", "_single", "super"], "constants": [], "modules": [], "extends": ["_ConvNd"], "imports": ["module", null, "math", "lazy", "warnings", "utils", "typing", "torch", "common_types", "torch._torch_docs"], "module_info": [{"import_identifier": "torch.nn.parameter", "module_name": "torch.nn", "object_name": "parameter", "classes": ["_ParameterMeta", "Parameter", "UninitializedTensorMixin", "UninitializedParameter", "UninitializedBuffer"], "functions": ["is_lazy"]}], "refs": ["/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/lib-dynload/math.cpython-39-darwin.so", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", null, null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py"], "meta": {"object_name": "Conv1d", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/modules/conv.py", "module_name": "torch.nn.modules.conv", "module_identifier": "torch.nn.modules.conv.Conv1d"}}, "torch.nn.modules.conv.Conv2d": {"classes": ["Optional", "Tensor", "F", "Union"], "functions": ["forward", "_pair", "isinstance", "_conv_forward", "super"], "constants": [], "modules": [], "extends": ["_ConvNd"], "imports": ["module", null, "math", "lazy", "warnings", "utils", "typing", "torch", "common_types", "torch._torch_docs"], "module_info": [{"import_identifier": "torch.nn.parameter", "module_name": "torch.nn", "object_name": "parameter", "classes": ["_ParameterMeta", "Parameter", "UninitializedTensorMixin", "UninitializedParameter", "UninitializedBuffer"], "functions": ["is_lazy"]}], "refs": ["/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/lib-dynload/math.cpython-39-darwin.so", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", null, null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py"], "meta": {"object_name": "Conv2d", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/modules/conv.py", "module_name": "torch.nn.modules.conv", "module_identifier": "torch.nn.modules.conv.Conv2d"}}, "torch.nn.modules.conv.Conv3d": {"classes": ["Optional", "Tensor", "F", "Union"], "functions": ["_triple", "forward", "isinstance", "_conv_forward", "super"], "constants": [], "modules": [], "extends": ["_ConvNd"], "imports": ["module", null, "math", "lazy", "warnings", "utils", "typing", "torch", "common_types", "torch._torch_docs"], "module_info": [{"import_identifier": "torch.nn.parameter", "module_name": "torch.nn", "object_name": "parameter", "classes": ["_ParameterMeta", "Parameter", "UninitializedTensorMixin", "UninitializedParameter", "UninitializedBuffer"], "functions": ["is_lazy"]}], "refs": ["/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/lib-dynload/math.cpython-39-darwin.so", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", null, null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py"], "meta": {"object_name": "Conv3d", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/modules/conv.py", "module_name": "torch.nn.modules.conv", "module_identifier": "torch.nn.modules.conv.Conv3d"}}, "torch.nn.functional.relu": {"classes": ["relu_", "relu"], "functions": ["relu_", "relu", "has_torch_function_unary", "handle_torch_function"], "constants": [false, "relu(input, inplace=False) -> Tensor\\n\\n    Applies the rectified linear unit function element-wise. See\\n    :class:`~torch.nn.ReLU` for more details.\\n    "], "modules": [], "extends": [], "imports": ["_jit_internal", "modules", null, "math", "warnings", "overrides", "typing", "torch", "torch._torch_docs", "modules.utils"], "module_info": [{"import_identifier": "torch._C", "module_name": "torch", "object_name": "_C", "classes": ["SymInt", "SymFloat", "SymBool", "ByteStorage", "DoubleStorage", "FloatStorage", "HalfStorage", "LongStorage", "IntStorage", "ShortStorage", "CharStorage", "BoolStorage", "BFloat16Storage", "ComplexDoubleStorage", "ComplexFloatStorage", "QUInt8Storage", "QInt8Storage", "QInt32Storage", "QUInt4x2Storage", "QUInt2x4Storage", "_TorchCompileInductorWrapper"], "functions": ["_preload_cuda_deps", "_load_global_deps", "sym_not", "sym_float", "sym_int", "sym_max", "sym_min", "typename", "is_tensor", "is_storage", "set_default_device", "set_default_tensor_type", "set_default_dtype", "use_deterministic_algorithms", "are_deterministic_algorithms_enabled", "is_deterministic_algorithms_warn_only_enabled", "set_deterministic_debug_mode", "get_deterministic_debug_mode", "get_float32_matmul_precision", "set_float32_matmul_precision", "set_warn_always", "is_warn_always_enabled", "manager_path", "_assert", "compiled_with_cxx11_abi", "compile", "_register_device_module", "_sparse_coo_tensor_unsafe"]}, {"import_identifier": "torch.types", "module_name": "torch", "object_name": "types", "classes": ["SymInt", "Storage"], "functions": []}], "refs": [null, "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/lib-dynload/math.cpython-39-darwin.so", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py", null], "meta": {"object_name": "relu", "object_type": "Function", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/functional.py", "module_name": "torch.nn.functional", "module_identifier": "torch.nn.functional.relu"}}, "torch.nn.functional.threshold": {"classes": [], "functions": [], "constants": [], "modules": [], "extends": [], "imports": ["_jit_internal", "modules", null, "math", "warnings", "overrides", "typing", "torch", "torch._torch_docs", "modules.utils"], "module_info": [{"import_identifier": "torch._C", "module_name": "torch", "object_name": "_C", "classes": ["SymInt", "SymFloat", "SymBool", "ByteStorage", "DoubleStorage", "FloatStorage", "HalfStorage", "LongStorage", "IntStorage", "ShortStorage", "CharStorage", "BoolStorage", "BFloat16Storage", "ComplexDoubleStorage", "ComplexFloatStorage", "QUInt8Storage", "QInt8Storage", "QInt32Storage", "QUInt4x2Storage", "QUInt2x4Storage", "_TorchCompileInductorWrapper"], "functions": ["_preload_cuda_deps", "_load_global_deps", "sym_not", "sym_float", "sym_int", "sym_max", "sym_min", "typename", "is_tensor", "is_storage", "set_default_device", "set_default_tensor_type", "set_default_dtype", "use_deterministic_algorithms", "are_deterministic_algorithms_enabled", "is_deterministic_algorithms_warn_only_enabled", "set_deterministic_debug_mode", "get_deterministic_debug_mode", "get_float32_matmul_precision", "set_float32_matmul_precision", "set_warn_always", "is_warn_always_enabled", "manager_path", "_assert", "compiled_with_cxx11_abi", "compile", "_register_device_module", "_sparse_coo_tensor_unsafe"]}, {"import_identifier": "torch.types", "module_name": "torch", "object_name": "types", "classes": ["SymInt", "Storage"], "functions": []}], "refs": [null, "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/lib-dynload/math.cpython-39-darwin.so", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py", null], "meta": {"object_name": "threshold", "object_type": "Function", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/functional.py", "module_name": "torch.nn.functional", "module_identifier": "torch.nn.functional.threshold"}}, "torch._tensor.Tensor": {"classes": ["RuntimeError", "Resize", "NotImplementedError", "Union", "Any", "LU", "Tuple", "AttributeError", "OrderedDict", "TypeError", "Number", "Tensor", "DLDeviceType", "Optional", "ValueError", "Dict", "NotImplemented"], "functions": ["resize_as", "eig", "unique_consecutive", "int", "backward", "TypeError", "_symeig", "solve", "getattr", "rename", "share_memory_", "resize", "ValueError", "resolve_ellipsis", "storage", "tuple", "list", "RuntimeError", "id", "norm", "update_names", "lstsq", "isinstance", "AttributeError", "single_ellipsis_index", "unzip_namedshape", "OrderedDict", "to_sparse_coo", "trim", "_update_names", "hasattr", "has_torch_function_variadic", "rename_", "handle_torch_function", "setattr", "func", "sorted", "NotImplementedError", "len", "_typed_storage", "_handle_torch_function_and_wrap_type_error_to_not_implemented", "dir", "check_serializing_named_tensor", "istft", "dict", "align_to", "unflatten", "all", "stft", "iter", "refine_names", "get_default_nowrap_functions", "split", "str", "_reduce_ex_internal", "is_ellipsis", "type", "has_torch_function_unary", "symeig", "register_hook", "storage_type", "unique", "_convert", "deepcopy", "issubclass", "super", "reinforce", "lu", "is_shared"], "constants": ["_C"], "modules": ["torch.autograd._functions", "_linalg_utils"], "extends": ["_TensorBase"], "imports": ["collections", "functools", "numbers", "warnings", "torch.utils.dlpack", "copy", "typing", "_linalg_utils", "enum", "torch", "copyreg"], "module_info": [{"import_identifier": "torch._C", "module_name": "torch", "object_name": "_C", "classes": ["SymInt", "SymFloat", "SymBool", "ByteStorage", "DoubleStorage", "FloatStorage", "HalfStorage", "LongStorage", "IntStorage", "ShortStorage", "CharStorage", "BoolStorage", "BFloat16Storage", "ComplexDoubleStorage", "ComplexFloatStorage", "QUInt8Storage", "QInt8Storage", "QInt32Storage", "QUInt4x2Storage", "QUInt2x4Storage", "_TorchCompileInductorWrapper"], "functions": ["_preload_cuda_deps", "_load_global_deps", "sym_not", "sym_float", "sym_int", "sym_max", "sym_min", "typename", "is_tensor", "is_storage", "set_default_device", "set_default_tensor_type", "set_default_dtype", "use_deterministic_algorithms", "are_deterministic_algorithms_enabled", "is_deterministic_algorithms_warn_only_enabled", "set_deterministic_debug_mode", "get_deterministic_debug_mode", "get_float32_matmul_precision", "set_float32_matmul_precision", "set_warn_always", "is_warn_always_enabled", "manager_path", "_assert", "compiled_with_cxx11_abi", "compile", "_register_device_module", "_sparse_coo_tensor_unsafe"]}, {"import_identifier": "torch.utils.dlpack", "module_name": "torch.utils", "object_name": "dlpack", "classes": ["DLDeviceType"], "functions": ["from_dlpack"]}, {"import_identifier": "torch.overrides", "module_name": "torch", "object_name": "overrides", "classes": ["TorchFunctionMode", "BaseTorchFunctionMode", "enable_reentrant_dispatch"], "functions": ["get_ignored_functions", "get_default_nowrap_functions", "get_testing_overrides", "wrap_torch_function", "_get_overloaded_args", "handle_torch_function", "_get_overridable_functions", "get_overridable_functions", "resolve_name", "_get_tensor_methods", "is_tensor_method_or_property", "is_tensor_like", "_get_current_function_mode", "_get_current_function_mode_stack", "_push_mode", "_pop_mode", "_pop_mode_temporarily", "get_buffer"]}, {"import_identifier": "torch.autograd._functions", "module_name": "torch.autograd", "object_name": "_functions", "classes": [], "functions": ["_calculate_shape", "_make_grads", "_tensor_or_tensors_to_tuple", "backward", "grad", "_is_checkpoint_valid", "variable", "_register_py_tensor_class_for_device"]}, {"import_identifier": "torch.utils.hooks", "module_name": "torch.utils", "object_name": "hooks", "classes": ["RemovableHandle", "BackwardHook"], "functions": ["unserializable_hook", "warn_if_has_hooks"]}, {"import_identifier": "torch._namedtensor_internals", "module_name": "torch", "object_name": "_namedtensor_internals", "classes": [], "functions": ["check_serializing_named_tensor", "build_dim_map", "unzip_namedshape", "namer_api_name", "is_ellipsis", "single_ellipsis_index", "expand_single_ellipsis", "replace_ellipsis_by_position", "resolve_ellipsis", "update_names_with_list", "update_names_with_mapping", "update_names"]}], "refs": ["/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/_C.cpython-39-darwin.so", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/copyreg.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/functools.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", null, null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/enum.py", "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/utils/hooks.py"], "meta": {"object_name": "Tensor", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/_tensor.py", "module_name": "torch._tensor", "module_identifier": "torch._tensor.Tensor"}}, "torch.nn.modules.rnn.RNNBase": {"classes": ["RuntimeError", "Module", "Tuple", "Parameter", "Tensor", "Optional", "List", "ValueError"], "functions": ["int", "float", "bool", "getattr", "permute_hidden", "ValueError", "list", "RuntimeError", "check_hidden_size", "isinstance", "hasattr", "_replicate_for_data_parallel", "setattr", "extra_repr", "len", "get_expected_hidden_size", "flatten_parameters", "_weights_have_changed", "_apply_permutation", "_apply", "ref", "check_forward_args", "check_input", "all_weights", "zip", "Parameter", "reset_parameters", "super", "_init_flat_weights", "range"], "constants": [], "modules": ["torch.backends.cudnn.rnn"], "extends": ["Module"], "imports": ["module", "numbers", null, "math", "warnings", "typing", "weakref", "torch", "parameter", "utils.rnn"], "module_info": [{"import_identifier": "torch.backends.cudnn.rnn", "module_name": "torch.backends.cudnn", "object_name": "rnn", "classes": ["Unserializable"], "functions": ["get_cudnn_mode", "init_dropout_state"]}], "refs": [null, "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/numbers.py", "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/backends/cudnn/rnn.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/lib-dynload/math.cpython-39-darwin.so", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/weakref.py"], "meta": {"object_name": "RNNBase", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/modules/rnn.py", "module_name": "torch.nn.modules.rnn", "module_identifier": "torch.nn.modules.rnn.RNNBase"}}, "torch.nn.modules.rnn.RNN": {"classes": ["RuntimeError", "PackedSequence", "Tuple", "ValueError", "Tensor", "Optional", "RNNBase"], "functions": ["RuntimeError", "forward", "PackedSequence", "int", "isinstance", "super", "ValueError"], "constants": ["_VF"], "modules": [], "extends": ["RNNBase"], "imports": ["module", "numbers", null, "math", "warnings", "typing", "weakref", "torch", "parameter", "utils.rnn"], "module_info": [{"import_identifier": "torch.backends.cudnn.rnn", "module_name": "torch.backends.cudnn", "object_name": "rnn", "classes": ["Unserializable"], "functions": ["get_cudnn_mode", "init_dropout_state"]}], "refs": [null, "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/numbers.py", "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/backends/cudnn/rnn.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/lib-dynload/math.cpython-39-darwin.so", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/weakref.py"], "meta": {"object_name": "RNN", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/modules/rnn.py", "module_name": "torch.nn.modules.rnn", "module_identifier": "torch.nn.modules.rnn.RNN"}}, "torch.nn.modules.rnn.LSTM": {"classes": ["RuntimeError", "PackedSequence", "Tuple", "Tensor", "Optional", "RNNBase"], "functions": ["RuntimeError", "forward", "PackedSequence", "check_forward_args", "int", "isinstance", "get_expected_cell_size", "permute_hidden", "_apply_permutation", "super"], "constants": ["_VF"], "modules": [], "extends": ["RNNBase"], "imports": ["module", "numbers", null, "math", "warnings", "typing", "weakref", "torch", "parameter", "utils.rnn"], "module_info": [{"import_identifier": "torch.backends.cudnn.rnn", "module_name": "torch.backends.cudnn", "object_name": "rnn", "classes": ["Unserializable"], "functions": ["get_cudnn_mode", "init_dropout_state"]}], "refs": [null, "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/numbers.py", "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/backends/cudnn/rnn.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/lib-dynload/math.cpython-39-darwin.so", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/weakref.py"], "meta": {"object_name": "LSTM", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/modules/rnn.py", "module_name": "torch.nn.modules.rnn", "module_identifier": "torch.nn.modules.rnn.LSTM"}}, "torch.nn.modules.rnn.GRU": {"classes": ["RuntimeError", "PackedSequence", "Tuple", "ValueError", "Tensor", "Optional", "RNNBase"], "functions": ["RuntimeError", "forward", "PackedSequence", "int", "isinstance", "super", "ValueError"], "constants": ["_VF"], "modules": [], "extends": ["RNNBase"], "imports": ["module", "numbers", null, "math", "warnings", "typing", "weakref", "torch", "parameter", "utils.rnn"], "module_info": [{"import_identifier": "torch.backends.cudnn.rnn", "module_name": "torch.backends.cudnn", "object_name": "rnn", "classes": ["Unserializable"], "functions": ["get_cudnn_mode", "init_dropout_state"]}], "refs": [null, "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/numbers.py", "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/backends/cudnn/rnn.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/lib-dynload/math.cpython-39-darwin.so", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/weakref.py"], "meta": {"object_name": "GRU", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/modules/rnn.py", "module_name": "torch.nn.modules.rnn", "module_identifier": "torch.nn.modules.rnn.GRU"}}, "torch.nn.modules.activation.Softmax": {"classes": ["Optional", "Module", "Tensor", "F"], "functions": ["super", "extra_repr", "forward", "hasattr"], "constants": [], "modules": [], "extends": ["Module"], "imports": ["module", null, "warnings", "typing", "linear", "torch"], "module_info": [{"import_identifier": "torch.nn.parameter", "module_name": "torch.nn", "object_name": "parameter", "classes": ["_ParameterMeta", "Parameter", "UninitializedTensorMixin", "UninitializedParameter", "UninitializedBuffer"], "functions": ["is_lazy"]}, {"import_identifier": "torch.nn.init", "module_name": "torch.nn", "object_name": "init", "classes": [], "functions": ["_no_grad_uniform_", "_no_grad_normal_", "_no_grad_trunc_normal_", "_no_grad_fill_", "_no_grad_zero_", "calculate_gain", "uniform_", "normal_", "trunc_normal_", "constant_", "ones_", "zeros_", "eye_", "dirac_", "_calculate_fan_in_and_fan_out", "xavier_uniform_", "xavier_normal_", "_calculate_correct_fan", "kaiming_uniform_", "kaiming_normal_", "orthogonal_", "sparse_", "_make_deprecate"]}], "refs": ["/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py"], "meta": {"object_name": "Softmax", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/modules/activation.py", "module_name": "torch.nn.modules.activation", "module_identifier": "torch.nn.modules.activation.Softmax"}}, "torch.nn.modules.activation.Softmin": {"classes": ["Optional", "Module", "Tensor", "F"], "functions": ["super", "extra_repr", "forward", "hasattr"], "constants": [], "modules": [], "extends": ["Module"], "imports": ["module", null, "warnings", "typing", "linear", "torch"], "module_info": [{"import_identifier": "torch.nn.parameter", "module_name": "torch.nn", "object_name": "parameter", "classes": ["_ParameterMeta", "Parameter", "UninitializedTensorMixin", "UninitializedParameter", "UninitializedBuffer"], "functions": ["is_lazy"]}, {"import_identifier": "torch.nn.init", "module_name": "torch.nn", "object_name": "init", "classes": [], "functions": ["_no_grad_uniform_", "_no_grad_normal_", "_no_grad_trunc_normal_", "_no_grad_fill_", "_no_grad_zero_", "calculate_gain", "uniform_", "normal_", "trunc_normal_", "constant_", "ones_", "zeros_", "eye_", "dirac_", "_calculate_fan_in_and_fan_out", "xavier_uniform_", "xavier_normal_", "_calculate_correct_fan", "kaiming_uniform_", "kaiming_normal_", "orthogonal_", "sparse_", "_make_deprecate"]}], "refs": ["/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py"], "meta": {"object_name": "Softmin", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/modules/activation.py", "module_name": "torch.nn.modules.activation", "module_identifier": "torch.nn.modules.activation.Softmin"}}, "torch.nn.modules.activation.MultiheadAttention": {"classes": ["Module", "F", "Tuple", "NonDynamicallyQuantizableLinear", "Parameter", "AssertionError", "Tensor", "Optional"], "functions": ["forward", "xavier_normal_", "all", "constant_", "xavier_uniform_", "merge_masks", "NonDynamicallyQuantizableLinear", "Parameter", "AssertionError", "_reset_parameters", "str", "super", "any"], "constants": [], "modules": [], "extends": ["Module"], "imports": ["module", null, "warnings", "typing", "linear", "torch.nn.parameter", "torch"], "module_info": [{"import_identifier": "torch.nn.parameter", "module_name": "torch.nn", "object_name": "parameter", "classes": ["_ParameterMeta", "Parameter", "UninitializedTensorMixin", "UninitializedParameter", "UninitializedBuffer"], "functions": ["is_lazy"]}, {"import_identifier": "torch.nn.init", "module_name": "torch.nn", "object_name": "init", "classes": [], "functions": ["_no_grad_uniform_", "_no_grad_normal_", "_no_grad_trunc_normal_", "_no_grad_fill_", "_no_grad_zero_", "calculate_gain", "uniform_", "normal_", "trunc_normal_", "constant_", "ones_", "zeros_", "eye_", "dirac_", "_calculate_fan_in_and_fan_out", "xavier_uniform_", "xavier_normal_", "_calculate_correct_fan", "kaiming_uniform_", "kaiming_normal_", "orthogonal_", "sparse_", "_make_deprecate"]}], "refs": ["/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py"], "meta": {"object_name": "MultiheadAttention", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/modules/activation.py", "module_name": "torch.nn.modules.activation", "module_identifier": "torch.nn.modules.activation.MultiheadAttention"}}, "torch.nn.modules.transformer.TransformerEncoderLayer": {"classes": ["Module", "LayerNorm", "Linear", "Union", "F", "Dropout", "MultiheadAttention", "Tensor", "Optional", "Callable"], "functions": ["forward", "_ff_block", "Linear", "all", "_get_activation_fn", "isinstance", "Dropout", "MultiheadAttention", "hasattr", "str", "super", "any", "LayerNorm", "_sa_block"], "constants": [], "modules": [], "extends": ["Module"], "imports": ["module", null, "copy", "typing", "activation", "init", "dropout", "container", "torch", "linear", "normalization"], "module_info": [], "refs": ["/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/copy.py", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py"], "meta": {"object_name": "TransformerEncoderLayer", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py", "module_name": "torch.nn.modules.transformer", "module_identifier": "torch.nn.modules.transformer.TransformerEncoderLayer"}}, "torch.nn.modules.transformer.TransformerDecoderLayer": {"classes": ["Module", "LayerNorm", "Linear", "Union", "F", "Dropout", "MultiheadAttention", "Tensor", "Optional", "Callable"], "functions": ["_mha_block", "forward", "_ff_block", "Linear", "_get_activation_fn", "isinstance", "Dropout", "MultiheadAttention", "super", "LayerNorm", "_sa_block"], "constants": [], "modules": [], "extends": ["Module"], "imports": ["module", null, "copy", "typing", "activation", "init", "dropout", "container", "torch", "linear", "normalization"], "module_info": [], "refs": ["/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/copy.py", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py"], "meta": {"object_name": "TransformerDecoderLayer", "object_type": "Class", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py", "module_name": "torch.nn.modules.transformer", "module_identifier": "torch.nn.modules.transformer.TransformerDecoderLayer"}}, "torch.nn.functional.softmax": {"classes": ["dim", "softmax"], "functions": ["has_torch_function_unary", "dim", "softmax", "handle_torch_function", "_get_softmax_dim"], "constants": ["Applies a softmax function.\\n\\n    Softmax is defined as:\\n\\n    :math:`\\\\text{Softmax}(x_{i}) = \\\\frac{\\\\exp(x_i)}{\\\\sum_j \\\\exp(x_j)}`\\n\\n    It is applied to all slices along dim, and will re-scale them so that the elements\\n    lie in the range `[0, 1]` and sum to 1.\\n\\n    See :class:`~torch.nn.Softmax` for more details.\\n\\n    Args:\\n        input (Tensor): input\\n        dim (int): A dimension along which softmax will be computed.\\n        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\\n          If specified, the input tensor is casted to :attr:`dtype` before the operation\\n          is performed. This is useful for preventing data type overflows. Default: None.\\n\\n    .. note::\\n        This function doesn't work directly with NLLLoss,\\n        which expects the Log to be computed between the Softmax and itself.\\n        Use log_softmax instead (it's faster and has better numerical properties).\\n\\n    ", 3, null, "softmax"], "modules": [], "extends": [], "imports": ["_jit_internal", "modules", null, "math", "warnings", "overrides", "typing", "torch", "torch._torch_docs", "modules.utils"], "module_info": [{"import_identifier": "torch._C", "module_name": "torch", "object_name": "_C", "classes": ["SymInt", "SymFloat", "SymBool", "ByteStorage", "DoubleStorage", "FloatStorage", "HalfStorage", "LongStorage", "IntStorage", "ShortStorage", "CharStorage", "BoolStorage", "BFloat16Storage", "ComplexDoubleStorage", "ComplexFloatStorage", "QUInt8Storage", "QInt8Storage", "QInt32Storage", "QUInt4x2Storage", "QUInt2x4Storage", "_TorchCompileInductorWrapper"], "functions": ["_preload_cuda_deps", "_load_global_deps", "sym_not", "sym_float", "sym_int", "sym_max", "sym_min", "typename", "is_tensor", "is_storage", "set_default_device", "set_default_tensor_type", "set_default_dtype", "use_deterministic_algorithms", "are_deterministic_algorithms_enabled", "is_deterministic_algorithms_warn_only_enabled", "set_deterministic_debug_mode", "get_deterministic_debug_mode", "get_float32_matmul_precision", "set_float32_matmul_precision", "set_warn_always", "is_warn_always_enabled", "manager_path", "_assert", "compiled_with_cxx11_abi", "compile", "_register_device_module", "_sparse_coo_tensor_unsafe"]}, {"import_identifier": "torch.types", "module_name": "torch", "object_name": "types", "classes": ["SymInt", "Storage"], "functions": []}], "refs": [null, "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/lib-dynload/math.cpython-39-darwin.so", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py", null], "meta": {"object_name": "softmax", "object_type": "Function", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/functional.py", "module_name": "torch.nn.functional", "module_identifier": "torch.nn.functional.softmax"}}, "torch.nn.functional.softmin": {"classes": ["dim", "softmax"], "functions": ["has_torch_function_unary", "dim", "softmax", "handle_torch_function", "_get_softmax_dim"], "constants": ["Applies a softmin function.\\n\\n    Note that :math:`\\\\text{Softmin}(x) = \\\\text{Softmax}(-x)`. See softmax definition for mathematical formula.\\n\\n    See :class:`~torch.nn.Softmin` for more details.\\n\\n    Args:\\n        input (Tensor): input\\n        dim (int): A dimension along which softmin will be computed (so every slice\\n            along dim will sum to 1).\\n        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\\n          If specified, the input tensor is casted to :attr:`dtype` before the operation\\n          is performed. This is useful for preventing data type overflows. Default: None.\\n    ", 3, null, "softmin"], "modules": [], "extends": [], "imports": ["_jit_internal", "modules", null, "math", "warnings", "overrides", "typing", "torch", "torch._torch_docs", "modules.utils"], "module_info": [{"import_identifier": "torch._C", "module_name": "torch", "object_name": "_C", "classes": ["SymInt", "SymFloat", "SymBool", "ByteStorage", "DoubleStorage", "FloatStorage", "HalfStorage", "LongStorage", "IntStorage", "ShortStorage", "CharStorage", "BoolStorage", "BFloat16Storage", "ComplexDoubleStorage", "ComplexFloatStorage", "QUInt8Storage", "QInt8Storage", "QInt32Storage", "QUInt4x2Storage", "QUInt2x4Storage", "_TorchCompileInductorWrapper"], "functions": ["_preload_cuda_deps", "_load_global_deps", "sym_not", "sym_float", "sym_int", "sym_max", "sym_min", "typename", "is_tensor", "is_storage", "set_default_device", "set_default_tensor_type", "set_default_dtype", "use_deterministic_algorithms", "are_deterministic_algorithms_enabled", "is_deterministic_algorithms_warn_only_enabled", "set_deterministic_debug_mode", "get_deterministic_debug_mode", "get_float32_matmul_precision", "set_float32_matmul_precision", "set_warn_always", "is_warn_always_enabled", "manager_path", "_assert", "compiled_with_cxx11_abi", "compile", "_register_device_module", "_sparse_coo_tensor_unsafe"]}, {"import_identifier": "torch.types", "module_name": "torch", "object_name": "types", "classes": ["SymInt", "Storage"], "functions": []}], "refs": [null, "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/warnings.py", "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/lib-dynload/math.cpython-39-darwin.so", null, "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/__init__.py", null], "meta": {"object_name": "softmin", "object_type": "Function", "abs_file_path": "/Users/yasin/PycharmProjects/ar-pytorch/venv/lib/python3.9/site-packages/torch/nn/functional.py", "module_name": "torch.nn.functional", "module_identifier": "torch.nn.functional.softmin"}}}